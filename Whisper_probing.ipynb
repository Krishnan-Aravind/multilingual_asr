{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import BartForConditionalGeneration\n",
    "from datasets import Audio, load_dataset\n",
    "import pandas \n",
    "import numpy\n",
    "import tqdm\n",
    "import torch\n",
    "import librosa\n",
    "from IPython.display import Audio\n",
    "from transformers import WhisperProcessor\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Input, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset fleurs (/root/.cache/huggingface/datasets/google___fleurs/hi_in/2.0.0/af82dbec419a815084fa63ebd5d5a9f24a6e9acdf9887b9e3b8c6bbd64e0b7ac)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['id', 'num_samples', 'path', 'audio', 'transcription', 'raw_transcription', 'gender', 'lang_id', 'language', 'lang_group_id'],\n",
      "        num_rows: 418\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "fleurs = DatasetDict()\n",
    "\n",
    "fleurs[\"test\"] = load_dataset(\"google/fleurs\", \"hi_in\", split=\"test\")\n",
    "\n",
    "print(fleurs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "# load model and processor\n",
    "\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\",output_hidden_states=True).cuda()\n",
    "\n",
    "model.config.forced_decoder_ids =  processor.get_decoder_prompt_ids(language=\"hindi\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing one input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1353: UserWarning: Using `max_length`'s default (448) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<|startoftranscript|><|hi|><|transcribe|><|notimestamps|> अग्वो में आज्द्टर केंद्रख होता है, जिसका मतला भी आजा की उन्मे थोडे या बिना किसी जटके से तुटनें की प्रवत्ती होती है.<|endoftext|>']\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "audio=fleurs['test'][i]['audio']['array']\n",
    "sr=fleurs['test'][i]['audio']['sampling_rate']\n",
    "transcription=fleurs['test'][i]['transcription']\n",
    "labels=torch.tensor(processor.tokenizer(fleurs['test'][i]['transcription']).input_ids).cuda()\n",
    "input_features = processor(audio, sampling_rate=sr, return_tensors=\"pt\").input_features.cuda()\n",
    "predicted_ids = model.generate(input_features)\n",
    "\n",
    "# decode token ids to text\n",
    "transcription = processor.batch_decode(predicted_ids, skip_special_tokens=False)\n",
    "print(transcription)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                       \r"
     ]
    }
   ],
   "source": [
    "def prepare_dataset(batch):\n",
    "    # load and resample audio data from 48 to 16kHz\n",
    "    audio = batch[\"audio\"]\n",
    "\n",
    "    # compute log-Mel input features from input audio array \n",
    "    batch[\"input_features\"] = processor.feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
    "\n",
    "    # encode target text to label ids \n",
    "    batch[\"labels\"] = processor.tokenizer(batch[\"transcription\"]).input_ids\n",
    "    return batch\n",
    "fleurs_processed = fleurs.map(prepare_dataset, remove_columns=fleurs.column_names[\"test\"], num_proc=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining DataCollator for batched inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 80, 3000])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
    "        # first treat the audio inputs by simply returning torch tensors\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\",return_attention_mask=True).to(device)\n",
    "\n",
    "        # get the tokenized label sequences\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        # pad the labels to max length\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        # if bos token is appended in previous tokenization step,\n",
    "        # cut bos token here as it's append later anyways\n",
    "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels.to(device)\n",
    "\n",
    "        return batch\n",
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)\n",
    "data_collator([fleurs_processed['test'][2]])['input_features'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    input_batch=data_collator([fleurs_processed['test'][2]])\n",
    "    output=model(**input_batch)\n",
    "    raw_embeddings=output['encoder_hidden_states'][0]\n",
    "\n",
    "    ## Note, There is no implementatoin here that accounts for attention mask. This needs to be done later in batching\n",
    "    ## In particular, the embeddings have tp be multiplied with the attention mask before averaging. \n",
    "    mean_pooled = raw_embeddings.sum(axis=1) / input_batch['attention_mask'].sum(axis=-1).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.2079e-01, -4.0981e-01, -5.3685e-01, -1.8853e+00, -1.2916e-01,\n",
       "          1.3243e+01, -2.4261e-01, -1.3180e-01, -1.1218e-01, -1.5345e-01,\n",
       "         -1.1883e-01, -4.6020e-01,  1.6376e+01, -9.7700e-02, -7.0510e-01,\n",
       "         -3.1490e-01, -1.9867e-01,  2.5166e+00, -6.8524e-01,  1.2408e+01,\n",
       "         -1.8797e-01, -1.9481e-01, -3.5793e-01, -1.8992e-02, -3.0768e-01,\n",
       "         -4.3020e-01, -1.3105e-01, -2.0492e-01, -1.0976e-01, -2.4197e-01,\n",
       "         -6.5150e-01, -2.9447e-01, -1.2303e-01, -1.1385e-01, -1.3264e-01,\n",
       "         -2.0747e-01, -3.1276e-01, -4.7822e-01, -2.5880e-01, -1.2137e-01,\n",
       "         -1.5816e-01, -6.0059e-01, -2.2619e-01, -5.1787e-01, -1.5846e-01,\n",
       "         -1.2401e-01, -7.6439e-01, -4.1079e-02, -4.2156e-01, -1.6939e-01,\n",
       "         -1.6054e-01, -1.4394e-01, -3.7949e-01, -6.8554e-01, -1.6783e-01,\n",
       "         -1.1361e-01, -1.4607e-01,  1.2074e+01, -2.6806e-01, -2.9099e-01,\n",
       "         -6.5096e-02,  3.6805e+00,  9.1759e+00, -4.0561e-01, -1.3031e-01,\n",
       "         -4.5442e-01,  2.4091e-02, -5.7477e-02, -1.8778e-01, -3.2792e-01,\n",
       "         -2.1474e-01,  2.1639e+01, -3.1003e-01, -5.6303e-01, -4.6442e-02,\n",
       "         -1.7831e-02, -1.0944e+00, -9.4120e-02, -1.5984e-01, -1.3207e-01,\n",
       "         -1.1376e-01, -2.2874e-01, -7.3029e-02, -6.2460e-03, -2.8809e-01,\n",
       "         -1.8171e-01,  8.1942e-01,  2.3472e-02, -9.9382e-02, -7.7106e-02,\n",
       "          1.4904e-01, -1.8970e+00,  4.6079e+00, -1.0048e+00,  1.2366e-02,\n",
       "          7.1991e-01,  1.2226e-01,  1.7970e-02,  3.3975e+00, -6.2401e-03,\n",
       "          2.5808e-01, -2.7893e-02,  4.8085e+00, -7.8832e-01, -1.9223e+00,\n",
       "         -2.1849e-01,  1.4480e+01, -1.0550e-02,  2.3461e+00,  5.5792e+00,\n",
       "         -7.0330e-01, -1.1120e-02,  1.8218e+01, -2.4199e+00, -1.0403e+00,\n",
       "          6.7017e+00,  1.4057e-01,  1.2874e-01, -7.3606e-01,  5.3780e+00,\n",
       "          9.5678e+00,  1.2347e+01,  9.3273e-01, -2.5354e+00, -4.8287e-01,\n",
       "          1.8162e+00,  8.2598e+00,  6.3551e+00,  1.6095e+00,  3.5504e-01,\n",
       "          2.7227e-01, -1.4172e-01, -1.7797e+00,  5.0964e+00,  2.8159e+00,\n",
       "          1.5066e+00, -5.4071e-01, -1.2881e+00,  4.0305e-01, -2.4924e+00,\n",
       "          6.5276e-01, -3.9125e-01,  7.5679e-01,  2.6160e-02, -5.3532e-01,\n",
       "         -2.3343e+00, -2.9323e+00,  1.5915e+01,  1.3659e+01,  8.2624e+00,\n",
       "          1.0461e+01, -3.1115e-02,  1.1629e+01,  2.0162e+01,  5.0259e+00,\n",
       "          9.5624e+00,  5.9149e-01,  1.5050e+01,  7.2263e+00,  3.0167e+00,\n",
       "         -8.0722e-01,  1.4291e+01,  6.8695e-01,  3.0035e-01,  1.7057e+01,\n",
       "          2.0422e-01,  6.0363e-01,  7.9795e+00,  1.5150e+01,  5.5244e+00,\n",
       "         -1.0377e-01,  3.0775e-01,  2.3777e+01,  5.4970e+00,  7.0041e-01,\n",
       "          1.0935e+00,  7.0583e+00,  1.1371e+01, -7.4899e-01,  2.6013e+00,\n",
       "          2.1554e+01,  9.3248e+00, -1.1098e+00,  1.1171e+01, -2.6062e+00,\n",
       "          4.6136e-02,  3.0725e+00,  1.0804e+00, -2.9271e-01,  2.0226e+00,\n",
       "         -4.9349e-01,  2.1987e+00,  1.9381e+00,  5.0596e+00,  1.2353e+00,\n",
       "          7.4590e-01,  2.4936e-01, -2.4335e+00, -9.8061e-01,  2.9009e+00,\n",
       "         -2.1045e-01,  1.1581e-01,  3.6164e-01, -3.4673e-01,  1.0252e+01,\n",
       "          1.5536e+00,  2.1987e+00,  1.3051e+00,  2.5426e+00,  1.3634e+00,\n",
       "          3.7522e+00,  3.6720e+00,  2.2334e+00,  3.2008e+00,  2.8654e+00,\n",
       "          3.0814e+00,  2.4937e+00,  6.6027e-01,  2.0049e+00,  2.1402e+01,\n",
       "          1.2289e+00,  5.1365e+00, -6.5856e-01,  4.7799e+00,  6.9202e-01,\n",
       "          3.3834e+00,  5.1267e+00, -1.4633e+00,  3.3147e-01, -2.9477e+00,\n",
       "         -6.0615e-01,  1.2723e+01,  7.2867e-02,  9.3690e-01, -1.5215e+00,\n",
       "          1.7469e+00,  7.1329e+00,  1.9910e+01,  3.8668e+00,  3.0954e+00,\n",
       "          4.8914e+00,  2.5536e+00,  2.2913e+00,  3.3677e+00,  3.6053e+00,\n",
       "          5.9700e+00,  8.8514e+00,  6.9428e+00,  8.2614e+00,  6.8411e+00,\n",
       "          1.6101e+01,  8.9920e+00,  7.6225e+00,  8.0937e+00,  1.2678e+01,\n",
       "          1.0055e+01,  8.6809e+00,  1.0699e+01,  2.3414e+01,  1.0431e+01,\n",
       "          1.3154e+01,  1.1683e+01,  1.0419e+01,  1.0257e+01,  1.1945e+01,\n",
       "          1.1465e+01,  1.0938e+01,  2.6664e+01,  1.7570e+01,  1.3960e+01,\n",
       "          1.2158e+01,  1.1303e+01,  1.0352e+01,  1.2032e+01,  3.4514e+01,\n",
       "          1.6426e+01,  1.1458e+01,  1.1630e+01,  1.5889e+01,  1.0106e+01,\n",
       "          1.6908e+01,  1.4232e+01,  9.3226e+00,  1.9217e+01,  1.0465e+01,\n",
       "          1.0743e+01,  1.0187e+01,  1.9163e+01,  1.0293e+01,  1.1691e+01,\n",
       "          8.1419e+00,  1.0050e+01,  1.0215e+01,  9.1665e+00,  9.1850e+00,\n",
       "          9.0687e+00,  2.4254e+01,  1.5555e+01,  1.1948e+01,  7.4286e+00,\n",
       "          9.9473e+00,  1.1036e+01,  1.5667e+01,  1.4456e+01,  1.1510e+01,\n",
       "          1.4676e+01,  1.0622e+01,  7.4590e+00,  6.0602e+00,  5.3694e+00,\n",
       "          1.2082e+01,  6.6556e+00,  5.6781e+00,  1.5234e+01,  9.3808e+00,\n",
       "          4.6731e+00,  8.3193e+00,  8.6538e+00,  1.8958e+01,  9.0328e+00,\n",
       "          1.0712e+01,  8.0348e+00,  3.7531e+00,  4.4536e+00,  4.5223e+00,\n",
       "          1.2221e+01,  2.3200e+00,  2.9484e+00,  4.9652e+00,  4.4139e+00,\n",
       "          6.3375e+00,  1.0301e+01,  1.6591e+00,  2.4011e+00,  1.9398e+00,\n",
       "          1.3094e+01,  8.4382e+00,  9.5865e+00,  1.8083e+01,  1.3524e+00,\n",
       "          7.9176e+00,  1.3227e+01,  2.0594e+00,  7.9367e+00,  9.5645e+00,\n",
       "          1.6415e+01,  4.3890e+00,  1.0364e+01,  2.2610e+00,  2.0078e+00,\n",
       "          1.3864e+00,  7.0792e+00,  1.4873e+01,  7.7451e+00,  9.8755e+00,\n",
       "          1.6103e+00,  1.4438e+01,  1.4963e+01,  1.6387e+00,  2.3660e+00,\n",
       "          1.0286e+01,  7.2299e+00,  5.8152e-01,  2.8881e+00,  1.7334e+01,\n",
       "          5.8496e-01,  5.9526e+00,  1.7917e+00,  6.3059e+00,  3.4139e+00,\n",
       "          2.8610e-01,  1.0031e+01,  5.6934e-01, -1.5807e-01,  1.2803e+01,\n",
       "          8.3605e+00,  6.0983e+00,  1.1233e+01,  8.5323e+00, -4.3403e-01,\n",
       "          3.4600e+00,  2.9167e+00,  5.9114e-03, -1.8114e-01,  3.0385e+01,\n",
       "         -2.9323e-01, -1.0011e+00, -2.0067e+00, -6.1093e-01, -1.3140e-01,\n",
       "         -4.1192e-01, -1.1482e+00, -1.7255e-01, -2.7332e-01, -1.5277e+00,\n",
       "         -4.8593e-01, -4.3706e-01, -2.4821e-01, -1.5704e-01, -6.0709e-01,\n",
       "         -3.5817e-01, -5.2734e-01, -3.0633e-01, -2.7289e-01, -3.0365e-01,\n",
       "         -2.8492e-01, -2.6851e-01, -7.9540e-02, -1.9748e+00, -3.0137e-01,\n",
       "         -3.4531e-01, -1.7872e+00, -2.7926e-01, -2.5292e-01, -1.1440e+00,\n",
       "         -4.0174e-01, -2.6463e-01, -1.3691e-01, -2.9113e-01, -2.5048e-01,\n",
       "         -4.8053e-01, -2.7125e-01, -2.9913e-01, -2.2761e-01, -2.9438e-01,\n",
       "          3.7874e+00, -1.6919e-01, -1.7772e+00, -1.2734e-01, -2.3849e-01,\n",
       "         -7.4457e-01, -2.6385e-03, -8.1035e-01, -1.9333e-01, -1.5782e-01,\n",
       "         -3.1706e-01, -2.4305e-01, -6.4576e-01, -2.1645e+00, -1.5987e+00,\n",
       "         -1.7219e-01, -2.1316e-01, -3.1995e-01, -3.9360e-01, -3.7068e-01,\n",
       "         -1.8790e-01, -2.3030e-01, -1.9793e-01, -1.7209e-01, -2.7866e-01,\n",
       "         -1.6474e-01, -2.2539e+00, -4.1090e-01, -2.7534e+00, -1.8189e-01,\n",
       "         -1.9642e-01, -1.8034e-01, -8.8998e-02, -2.0150e+00, -1.0174e-01,\n",
       "         -1.0605e-01, -7.5117e-01, -6.9428e-01, -2.8641e-01, -2.5084e-01,\n",
       "         -2.0800e-01, -3.6412e-01, -7.9433e-02, -2.5362e-01, -1.2675e-01,\n",
       "         -8.7570e-02, -1.1926e-01, -2.1050e-01, -6.3509e-01,  4.6521e-02,\n",
       "         -1.5081e-01, -1.5414e+00, -9.1979e-01, -8.4264e-02,  8.2663e+00,\n",
       "         -1.2453e-01,  8.8094e-02,  1.0654e+01,  4.6981e-02, -4.5161e-02,\n",
       "         -1.6751e-02, -2.3600e-01, -1.4337e+00, -2.9952e+00,  1.3622e+01,\n",
       "         -1.1628e+00,  4.5550e-01, -6.8594e-01, -2.1122e-01, -2.8457e+00,\n",
       "          1.3070e+01,  5.8787e+00, -1.8209e+00,  5.3028e+00,  2.0668e+00,\n",
       "         -2.0349e+00,  3.3542e+00,  6.5127e+00,  1.5117e+00,  5.5168e+00,\n",
       "         -6.6608e-02,  5.4480e+00, -1.8702e+00,  1.1128e+01, -2.3563e-01,\n",
       "         -2.9240e+00,  1.8378e+00,  2.3120e+00,  1.3427e+01, -8.1733e-01,\n",
       "          8.4059e+00,  2.6624e+00,  1.4400e+01,  8.5495e+00,  2.3531e+00,\n",
       "          1.8036e+01, -3.3156e+00,  1.3840e+01,  1.2006e-01,  1.7011e+01,\n",
       "          1.1764e+01, -6.0730e-01,  3.1457e+00,  9.5056e+00,  5.5212e+00,\n",
       "          3.5449e+00,  9.1304e+00, -2.0225e+00, -2.4193e+00,  1.4451e+01,\n",
       "          1.0639e+01,  1.5119e-02,  1.4150e+01, -4.0856e-01,  6.2560e+00,\n",
       "          3.0157e+00,  5.6057e+00,  7.2039e+00,  1.0524e+01,  2.0320e-01,\n",
       "         -1.2160e+00, -7.8861e-01,  2.5803e+01, -2.5313e+00,  1.4534e+01,\n",
       "          1.3302e+01,  1.0376e+00,  5.1158e-01,  3.0306e-01, -4.1460e-01,\n",
       "         -3.3676e+00, -7.7993e-01,  9.5885e+00, -1.4497e+00, -6.3114e-01,\n",
       "          8.9033e+00, -3.1508e-02,  1.2727e+01, -1.0776e+00, -1.8176e+00,\n",
       "          7.3517e+00,  1.8571e+00, -1.2169e+00,  6.0810e+00, -1.1082e+00,\n",
       "         -1.2732e+00, -1.0514e+00, -7.7661e-01,  3.0257e+01, -1.3370e-01,\n",
       "          4.7804e-01,  7.5389e-01,  1.1916e+00,  9.1562e-01,  7.3047e-01,\n",
       "          8.7451e-01,  5.7158e-01,  2.5457e-01, -3.3927e-01, -7.8472e-01,\n",
       "          1.2852e+01,  2.1821e+01, -2.9011e+00, -2.7109e-01, -3.9305e+00,\n",
       "         -1.5132e+00, -1.6073e+00, -3.1734e+00,  2.5377e+00, -2.4010e+00,\n",
       "         -2.9724e+00,  6.2687e-02, -9.8159e-01,  1.0756e+00,  4.4284e+00,\n",
       "         -4.2441e-01,  5.4253e+00,  3.2844e+00, -5.9689e-01, -4.7437e-01,\n",
       "          5.4635e+00,  1.0856e+01, -5.9737e-01,  5.3339e-02, -5.1604e-02,\n",
       "          2.6950e-01,  3.1341e+00,  1.4639e+01,  6.0994e+01,  1.3673e+01,\n",
       "         -3.0737e+00,  2.3712e+01,  8.9267e+00,  8.8758e+00,  1.3371e+01,\n",
       "          1.3607e+00, -4.7555e-01,  8.2441e+00,  3.7250e+01,  3.9784e+00,\n",
       "          4.1281e+01, -5.4665e+00,  4.7466e-01,  7.0576e+00,  1.7498e+00,\n",
       "          1.7868e+01,  5.8667e+00, -5.7980e+00,  2.0039e+00,  1.1851e+01,\n",
       "         -1.8869e+00,  2.1894e+01, -4.1566e+00, -3.0077e+00,  5.8651e+00,\n",
       "          8.2799e+00,  9.2461e+00,  3.2240e+00,  2.4272e+00,  4.1884e-01,\n",
       "         -2.0925e-01,  1.2177e+00,  2.5663e-01,  1.7265e+01,  3.4318e+00,\n",
       "          2.0563e+00,  1.4792e+01,  7.4397e+00,  1.2950e+01,  9.3127e+00,\n",
       "          5.2384e+00,  5.5422e+00,  4.7330e+00,  5.0535e+00,  8.8808e+00,\n",
       "          8.6131e+00,  1.2334e+01,  9.2872e+00,  2.0353e+01,  1.0546e+01,\n",
       "          7.8165e+00,  9.1834e+00,  9.6166e+00,  1.0227e+01,  1.0068e+01,\n",
       "          1.0093e+01,  1.7555e+01,  1.0344e+01,  1.0839e+01,  1.2965e+01,\n",
       "          1.1355e+01,  1.1754e+01,  1.3087e+01,  1.3634e+01,  1.2200e+01,\n",
       "          1.3292e+01,  1.2527e+01,  1.5723e+01,  1.2997e+01,  1.4431e+01,\n",
       "          1.2878e+01,  1.2536e+01,  1.4452e+01,  1.4152e+01,  2.3509e+01,\n",
       "          1.4536e+01,  1.8928e+01,  1.3449e+01,  1.3886e+01,  1.3757e+01,\n",
       "          1.4001e+01,  1.4227e+01,  1.5472e+01,  1.5235e+01,  1.5107e+01,\n",
       "          1.5004e+01,  1.5898e+01,  1.5672e+01,  1.4488e+01,  1.4638e+01,\n",
       "          1.6934e+01,  1.4785e+01,  1.5497e+01,  1.6869e+01,  1.6961e+01,\n",
       "          1.6176e+01,  1.5187e+01,  2.1554e+01,  1.9784e+01,  1.4696e+01,\n",
       "          2.3615e+01,  1.5494e+01,  1.8314e+01,  1.5330e+01,  1.6181e+01,\n",
       "          1.5356e+01,  1.5429e+01,  1.5548e+01,  1.5831e+01,  1.5691e+01,\n",
       "          1.5763e+01,  1.9932e+01,  1.5407e+01,  1.5380e+01,  1.5636e+01,\n",
       "          1.5650e+01,  1.5557e+01,  1.6170e+01,  1.5965e+01,  1.5262e+01,\n",
       "          2.3989e+01,  1.6292e+01,  1.5522e+01,  1.5472e+01,  1.5673e+01,\n",
       "          2.1446e+01,  1.6059e+01,  1.6229e+01,  1.5819e+01,  1.9583e+01,\n",
       "          1.6369e+01,  1.6066e+01,  1.7946e+01,  1.6478e+01,  1.6415e+01,\n",
       "          2.1459e+01,  2.9313e+01,  2.1369e+01,  1.5938e+01,  1.6610e+01,\n",
       "          1.6048e+01,  1.5454e+01,  1.8463e+01,  1.6082e+01,  1.6586e+01,\n",
       "          1.6254e+01,  1.6984e+01,  1.5707e+01,  1.6308e+01,  1.9361e+01,\n",
       "          1.8219e+01,  1.0028e+02,  3.0560e+01]], device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 80])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "# load model and processor\n",
    "\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\",output_hidden_states=True).cuda()\n",
    "\n",
    "\n",
    "class generate_layer_embeddings:\n",
    "    def __init__(language_id):\n",
    "        self.model=model\n",
    "        self.model.config.forced_decoder_ids =  processor.get_decoder_prompt_ids(language=language_id, task=\"transcribe\")\n",
    "        fleurs = DatasetDict()\n",
    "        fleurs[\"test\"] = load_dataset(\"google/fleurs\", \"hi_in\", split=\"test\")\n",
    "        fleurs[\"train\"] = load_dataset(\"google/fleurs\", \"hi_in\", split=\"train\")\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
